{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+FlSZ64ga8R7j1y3lSmKE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogyata-04/Handwritten-Emoji-Letter-Captcha-Detection/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "E6hIyDDtJCy6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozQe3KGmR6VP",
        "outputId": "dcb10a0b-f77a-4357-a7bd-4ab3a66df6f5"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path1 = '/content/drive/MyDrive/mosaic/model_emoji_dataset_final.h5'\n",
        "model_emoji= tf.keras.models.load_model(model_path1)\n",
        "model_path2='/content/drive/MyDrive/mosaic/model_letter_dataset_final.h5'\n",
        "model_letter=tf.keras.models.load_model(model_path2)"
      ],
      "metadata": {
        "id": "dWSOYjbBR-OK"
      },
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Enter the path of the image\")\n",
        "a = input()"
      ],
      "metadata": {
        "id": "V-Ek7wE1JbUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read and thresholded image\n",
        "image=cv2.imread(a)\n",
        "image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "_,thresh= cv2.threshold(image,100, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "img=cv2.copyMakeBorder(thresh,200,200,0,0,cv2.BORDER_CONSTANT,value=[255,255,255])\n",
        "img.shape\n",
        "\n",
        "#erode image\n",
        "kernal=cv2.getStructuringElement(cv2.MORPH_RECT,(3,13))\n",
        "erode=cv2.erode(img,kernal,iterations=10)\n",
        "\n",
        "#collecting the required contours in cnt_new\n",
        "cnts,_=cv2.findContours(erode, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
        "cnt_new=[]\n",
        "for num in range(len(cnts)):\n",
        "  if(cv2.contourArea(cnts[num])>2000):\n",
        "    cnt_new.append(cnts[num])\n",
        "\n",
        "#appending all the contour values in x and y matrix which updates from beginning after every iteration\n",
        "#then we have appended values in matrices xi,yi,xf,yf where xi is minimum x value of contour points and xf is maximum x value of contour points\n",
        "#and same for yi and yf as well\n",
        "xi=[]\n",
        "xf=[]\n",
        "yi=[]\n",
        "yf=[]\n",
        "for num in range(len(cnt_new)):\n",
        "  x=[]\n",
        "  for i in range(len(cnt_new[num])):\n",
        "    b=cnt_new[num][i][0][0]\n",
        "    x.append(b)\n",
        "  #print(x)\n",
        "  y=[]\n",
        "  for i in range(len(cnt_new[num])):\n",
        "    b=cnt_new[num][i][0][1]\n",
        "    y.append(b)\n",
        "\n",
        "  #print(cnt_new[num].shape)\n",
        "\n",
        "  y=np.array(y)\n",
        "  x=np.array(x)\n",
        "  y_=min(y)\n",
        "  y_h=max(y)\n",
        "  x_=min(x)\n",
        "  x_h=max(x)\n",
        "  xi.append(x_)\n",
        "  yi.append(y_)\n",
        "  xf.append(x_h)\n",
        "  yf.append(y_h)\n",
        "\n",
        "#swapping values of coordinates on the basis of xi to get required order of images\n",
        "for i in range(len(cnt_new)):\n",
        "  for j in range(i):\n",
        "    if(xi[i]<xi[j]):\n",
        "      temp=xi[i]\n",
        "      xi[i]=xi[j]\n",
        "      xi[j]=temp\n",
        "      temp=xf[i]\n",
        "      xf[i]=xf[j]\n",
        "      xf[j]=temp\n",
        "      temp=yi[i]\n",
        "      yi[i]=yi[j]\n",
        "      yi[j]=temp\n",
        "      temp=yf[i]\n",
        "      yf[i]=yf[j]\n",
        "      yf[j]=temp\n",
        "\n",
        "#appending images in parts on the basis of the swapped order above\n",
        "parts=[]\n",
        "for i in range(len(cnt_new)-1):\n",
        "  cropped_image = image[yi[i+1]-160:yf[i+1]-240,xi[i+1]:xf[i+1]]\n",
        "  parts.append(cropped_image)\n",
        "\n",
        "parts_new=[]\n",
        "img_data=[]\n",
        "for i in range(len(cnt_new)-1):\n",
        "\n",
        "  #_,thresh= cv2.threshold(parts[i],150, 255, cv2.THRESH_BINARY)\n",
        "  kernal=cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
        "  erode=cv2.erode(parts[i],kernal,iterations=1)\n",
        "  image=cv2.resize(erode, (28, 28),interpolation = cv2.INTER_AREA)\n",
        "  image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "  image = cv2.flip(image,0)\n",
        "  parts_new.append(image)\n",
        "  image=np.array(image)\n",
        "  image = image.astype('float32')\n",
        "  img_data.append(image)\n",
        "  cv2_imshow(image)\n",
        "img_data = np.array(img_data)\n",
        "img_data[img_data>100] = 255\n",
        "img_data[img_data<=100] = 0\n",
        "img_data=(255-img_data)/255"
      ],
      "metadata": {
        "id": "0WloKTUqJeqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dict_letter= {0:'A',1:'B',2:'D' ,3:'E',4:'F',5:'H',6:'J',7:'K',8:'L',9:'M',10:'N',11:'P',12:'R',13:'S',14:'T',15:'W',16:'X',17:'Y',18:'Z'}"
      ],
      "metadata": {
        "id": "Euffjuq6TMlV"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction of captcha\n",
        "prediction=[]\n",
        "for i in range(img_data.shape[0]):\n",
        "  image=img_data[i]\n",
        "  reshaped_arr=image.reshape((1, 28, 28, 1))\n",
        "  test1= model_emoji.predict(reshaped_arr)\n",
        "  test2= model_letter.predict(reshaped_arr)\n",
        "  result_confidence1=np.max(test1)\n",
        "  result_confidence2=np.max(test2)\n",
        "  result1= np.argmax(test1,axis = 1)\n",
        "  result2= np.argmax(test2,axis = 1)\n",
        "  print(result1)\n",
        "  print(result2)\n",
        "  print(result_confidence1)\n",
        "  print(result_confidence2)\n",
        "  if(result_confidence2>0.95):\n",
        "    #we consider it is emoji\n",
        "    prediction.append(my_dict_letter[result2[0]])\n",
        "  else:\n",
        "    image = cv2.flip(image,0)\n",
        "    image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    prediction.append(result1[0])\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "13X65PgSJ5Fy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}